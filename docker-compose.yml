version: "3.8"
services:
  spark_web:
    build:
      context: .
      args:
        - RAILS_ENV=production
    image: spark4_app
    environment:
      - BUILD=unknown
      - BUILD_DATE=unknown
      - WORKER_MODE=false
      - PIDFILE=/tmp/spark4.pid
      - RUBYOPT=-W:no-deprecated -W:no-experimental
      - RAILS_LOG_TO_STDOUT=yes_please
      - RAILS_SERVE_STATIC_FILES=yes_please
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - ./log.docker:/log
      - ./data.docker:/data
      - ./settings.local.docker.yml:/spark/config/settings.local.yml
    restart: on-failure
    labels:
      ofelia.enabled: "true"
      ofelia.job-exec.spark-sync.schedule: "@hourly"
      ofelia.job-exec.spark-sync.no-overlap: "true"
      ofelia.job-exec.spark-sync.command: "rake spark:sync"

  ofelia:
    image: mcuadros/ofelia:latest
    depends_on:
      - spark_web
    command: daemon --docker
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
#    labels:
#      ofelia.job-run.spark-sync.schedule: "@hourly"
#      ofelia.job-run.spark-sync.image: "spark4_app"
#      ofelia.job-run.spark-sync.command: "rake spark:sync"
#      ofelia.job-run.spark-sync.no-overlap: "true"
